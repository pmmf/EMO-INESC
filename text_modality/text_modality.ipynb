{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr\n",
    "import numpy\n",
    "import pandas\n",
    "\n",
    "def ccc(y_true, y_pred):\n",
    "    true_mean = np.mean(y_true)\n",
    "    true_variance = np.var(y_true)\n",
    "    pred_mean = np.mean(y_pred)\n",
    "    pred_variance = np.var(y_pred)\n",
    "\n",
    "    rho,_ = pearsonr(y_pred,y_true)\n",
    "\n",
    "    std_predictions = numpy.std(y_pred)\n",
    "\n",
    "    std_gt = numpy.std(y_true)\n",
    "\n",
    "\n",
    "    ccc = 2 * rho * std_gt * std_predictions / (\n",
    "        std_predictions ** 2 + std_gt ** 2 +\n",
    "        (pred_mean - true_mean) ** 2)\n",
    "\n",
    "    return ccc, rho\n",
    "\n",
    "def ccc_scorer(model, x, y):\n",
    "    preds = model.predict(x)\n",
    "    return ccc(y, preds)[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import os\n",
    "\n",
    "tr_X = pd.read_csv('omg_TrainTranscripts.csv').transcript.values.astype(np.str)\n",
    "tr_y = pd.read_csv('omg_TrainVideos.csv')\n",
    "val_X = pd.read_csv('omg_ValidationTranscripts.csv').transcript.values.astype(np.str)\n",
    "val_y = pd.read_csv('omg_ValidationVideos.csv')\n",
    "ts_X = pd.read_csv('omg_TestTranscripts.csv').transcript.values.astype(np.str)\n",
    "ts_y = pd.read_csv('omg_TestVideos_WithoutLabels.csv')\n",
    "\n",
    "tr_mask = tr_X != 'nan'\n",
    "val_mask = val_X != 'nan'\n",
    "ts_mask = ts_X != 'nan'\n",
    "\n",
    "tr_X = tr_X[tr_mask]\n",
    "tr_y = tr_y.loc[tr_mask]\n",
    "\n",
    "val_X = val_X[val_mask]\n",
    "val_y = val_y.loc[val_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.stem.porter import *\n",
    "\n",
    "stemmer = SnowballStemmer(\"english\")\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "def get_pos(X):\n",
    "    ret = []\n",
    "    for x in X:\n",
    "        _, next_x = zip(*nltk.pos_tag(x.split()))\n",
    "        next_x_lower = x#' '.join(next_x)#.lower()\n",
    "        next_x_stemmed = ' '.join(stemmer.stem(k) for k in x.lower())\n",
    "        next_x_pos = ' '.join(['POS::' + k for k in next_x])# + \\\n",
    "            #' ' + ' '.join(['POS::FIRST::' + k[0] for k in next_x])\n",
    "        ret.append(next_x_lower + ' ' +\n",
    "                   #next_x_stemmed + ' ' +\n",
    "                   next_x_pos)\n",
    "    ret = np.asarray(ret)\n",
    "    return ret\n",
    "\n",
    "tr_X_POS = get_pos(tr_X)\n",
    "val_X_POS = get_pos(val_X)\n",
    "ts_X_POS = get_pos(ts_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from nltk.sentiment.util import demo_sent_subjectivity\n",
    "from nltk.corpus import stopwords\n",
    "from textblob import TextBlob\n",
    "\n",
    "sid = SentimentIntensityAnalyzer()\n",
    "english_sw = set(stopwords.words('english'))\n",
    "negs = set(['not', 'no', 'doesn\\'t', 'don\\'t', 'didn\\'t', 'won\\'t', 'wouldn\\'t'])\n",
    "\n",
    "def get_extra(X):\n",
    "    ret = []\n",
    "    for x in X:\n",
    "        tks = x.lower().split()\n",
    "        num_stopwords = float(len([x for x in tks if x in english_sw])) / len(tks)\n",
    "        blob = TextBlob(x).sentiment\n",
    "        pol = sid.polarity_scores(x)\n",
    "        next_x = [pol[k] for k in ['neg', 'neu', 'pos', 'compound']] + \\\n",
    "            [(pol['pos'] + 1) / (pol['neg'] + 1), len(x.split()), num_stopwords,#, len(set(x.split()))\n",
    "             blob[0], blob[1], len([k for k in x if k == '*']), len([k for k in x if k == '*']) != 0,\n",
    "             len([k for k in tks if k in negs]),\n",
    "            ]\n",
    "        ret.append(next_x)\n",
    "    ret = np.asarray(ret)\n",
    "    return ret\n",
    "\n",
    "tr_vader = get_extra(tr_X)\n",
    "val_vader = get_extra(val_X)\n",
    "ts_vader = get_extra(ts_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "bow (InputLayer)                (None, 8977)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_107 (Dropout)           (None, 8977)         0           bow[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "fts (InputLayer)                (None, 12)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_316 (Dense)               (None, 10)           89780       dropout_107[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_317 (Dense)               (None, 5)            65          fts[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_106 (Concatenate)   (None, 15)           0           dense_316[0][0]                  \n",
      "                                                                 dense_317[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_318 (Dense)               (None, 1)            16          concatenate_106[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 89,861\n",
      "Trainable params: 89,861\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "Epoch 00001: val_my_ccc_loss improved from inf to 0.91654, saving model to model-valence.h5\n",
      "\n",
      "Epoch 00002: val_my_ccc_loss improved from 0.91654 to 0.85142, saving model to model-valence.h5\n",
      "\n",
      "Epoch 00003: val_my_ccc_loss improved from 0.85142 to 0.78136, saving model to model-valence.h5\n",
      "\n",
      "Epoch 00004: val_my_ccc_loss improved from 0.78136 to 0.75147, saving model to model-valence.h5\n",
      "\n",
      "Epoch 00005: val_my_ccc_loss did not improve\n",
      "\n",
      "Epoch 00006: val_my_ccc_loss did not improve\n",
      "\n",
      "Epoch 00007: val_my_ccc_loss did not improve\n",
      "\n",
      "Epoch 00008: val_my_ccc_loss did not improve\n",
      "\n",
      "Epoch 00009: val_my_ccc_loss did not improve\n",
      "\n",
      "Epoch 00010: val_my_ccc_loss did not improve\n",
      "\n",
      "Epoch 00011: val_my_ccc_loss did not improve\n",
      "\n",
      "Epoch 00012: val_my_ccc_loss did not improve\n",
      "\n",
      "Epoch 00013: val_my_ccc_loss did not improve\n",
      "\n",
      "Epoch 00014: val_my_ccc_loss did not improve\n",
      "\n",
      "Epoch 00015: val_my_ccc_loss did not improve\n",
      "\n",
      "Epoch 00016: val_my_ccc_loss did not improve\n",
      "\n",
      "Epoch 00017: val_my_ccc_loss did not improve\n",
      "\n",
      "Epoch 00018: val_my_ccc_loss did not improve\n",
      "\n",
      "Epoch 00019: val_my_ccc_loss did not improve\n",
      "\n",
      "Epoch 00020: val_my_ccc_loss did not improve\n",
      "\n",
      "Epoch 00021: val_my_ccc_loss did not improve\n",
      "\n",
      "Epoch 00022: val_my_ccc_loss did not improve\n",
      "\n",
      "Epoch 00023: val_my_ccc_loss did not improve\n",
      "\n",
      "Epoch 00024: val_my_ccc_loss did not improve\n",
      "\n",
      "Epoch 00025: val_my_ccc_loss did not improve\n",
      "\n",
      "Epoch 00026: val_my_ccc_loss did not improve\n",
      "\n",
      "Epoch 00027: val_my_ccc_loss did not improve\n",
      "\n",
      "Epoch 00028: val_my_ccc_loss did not improve\n",
      "\n",
      "Epoch 00029: val_my_ccc_loss did not improve\n",
      "\n",
      "Epoch 00030: val_my_ccc_loss did not improve\n",
      "\n",
      "Epoch 00031: val_my_ccc_loss did not improve\n",
      "\n",
      "Epoch 00032: val_my_ccc_loss did not improve\n",
      "\n",
      "Epoch 00033: val_my_ccc_loss did not improve\n",
      "\n",
      "Epoch 00034: val_my_ccc_loss did not improve\n",
      "\n",
      "Epoch 00035: val_my_ccc_loss did not improve\n",
      "\n",
      "Epoch 00036: val_my_ccc_loss did not improve\n",
      "\n",
      "Epoch 00037: val_my_ccc_loss did not improve\n",
      "\n",
      "Epoch 00038: val_my_ccc_loss did not improve\n",
      "\n",
      "Epoch 00039: val_my_ccc_loss did not improve\n",
      "\n",
      "Epoch 00040: val_my_ccc_loss did not improve\n",
      "\n",
      "Epoch 00041: val_my_ccc_loss did not improve\n",
      "\n",
      "Epoch 00042: val_my_ccc_loss did not improve\n",
      "\n",
      "Epoch 00043: val_my_ccc_loss did not improve\n",
      "\n",
      "Epoch 00044: val_my_ccc_loss did not improve\n",
      "\n",
      "Epoch 00045: val_my_ccc_loss did not improve\n",
      "\n",
      "Epoch 00046: val_my_ccc_loss did not improve\n",
      "\n",
      "Epoch 00047: val_my_ccc_loss did not improve\n",
      "\n",
      "Epoch 00048: val_my_ccc_loss did not improve\n",
      "\n",
      "Epoch 00049: val_my_ccc_loss did not improve\n",
      "\n",
      "Epoch 00050: val_my_ccc_loss did not improve\n",
      "valence 0.7202075702528223 0.06394458707685909 0.32883597310349605 0.1282146651892317\n",
      "\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "bow (InputLayer)                (None, 8977)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_108 (Dropout)           (None, 8977)         0           bow[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "fts (InputLayer)                (None, 12)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_319 (Dense)               (None, 10)           89780       dropout_108[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_320 (Dense)               (None, 5)            65          fts[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_107 (Concatenate)   (None, 15)           0           dense_319[0][0]                  \n",
      "                                                                 dense_320[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_321 (Dense)               (None, 1)            16          concatenate_107[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 89,861\n",
      "Trainable params: 89,861\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "Epoch 00001: val_my_ccc_loss improved from inf to 0.95232, saving model to model-arousal.h5\n",
      "\n",
      "Epoch 00002: val_my_ccc_loss improved from 0.95232 to 0.92799, saving model to model-arousal.h5\n",
      "\n",
      "Epoch 00003: val_my_ccc_loss improved from 0.92799 to 0.92343, saving model to model-arousal.h5\n",
      "\n",
      "Epoch 00004: val_my_ccc_loss did not improve\n",
      "\n",
      "Epoch 00005: val_my_ccc_loss did not improve\n",
      "\n",
      "Epoch 00006: val_my_ccc_loss improved from 0.92343 to 0.92314, saving model to model-arousal.h5\n",
      "\n",
      "Epoch 00007: val_my_ccc_loss improved from 0.92314 to 0.91943, saving model to model-arousal.h5\n",
      "\n",
      "Epoch 00008: val_my_ccc_loss improved from 0.91943 to 0.91908, saving model to model-arousal.h5\n",
      "\n",
      "Epoch 00009: val_my_ccc_loss did not improve\n",
      "\n",
      "Epoch 00010: val_my_ccc_loss did not improve\n",
      "\n",
      "Epoch 00011: val_my_ccc_loss did not improve\n",
      "\n",
      "Epoch 00012: val_my_ccc_loss did not improve\n",
      "\n",
      "Epoch 00013: val_my_ccc_loss did not improve\n",
      "\n",
      "Epoch 00014: val_my_ccc_loss improved from 0.91908 to 0.91856, saving model to model-arousal.h5\n",
      "\n",
      "Epoch 00015: val_my_ccc_loss improved from 0.91856 to 0.91679, saving model to model-arousal.h5\n",
      "\n",
      "Epoch 00016: val_my_ccc_loss improved from 0.91679 to 0.91485, saving model to model-arousal.h5\n",
      "\n",
      "Epoch 00017: val_my_ccc_loss did not improve\n",
      "\n",
      "Epoch 00018: val_my_ccc_loss did not improve\n",
      "\n",
      "Epoch 00019: val_my_ccc_loss did not improve\n",
      "\n",
      "Epoch 00020: val_my_ccc_loss did not improve\n",
      "\n",
      "Epoch 00021: val_my_ccc_loss did not improve\n",
      "\n",
      "Epoch 00022: val_my_ccc_loss did not improve\n",
      "\n",
      "Epoch 00023: val_my_ccc_loss did not improve\n",
      "\n",
      "Epoch 00024: val_my_ccc_loss did not improve\n",
      "\n",
      "Epoch 00025: val_my_ccc_loss did not improve\n",
      "\n",
      "Epoch 00026: val_my_ccc_loss did not improve\n",
      "\n",
      "Epoch 00027: val_my_ccc_loss did not improve\n",
      "\n",
      "Epoch 00028: val_my_ccc_loss did not improve\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00029: val_my_ccc_loss did not improve\n",
      "\n",
      "Epoch 00030: val_my_ccc_loss did not improve\n",
      "\n",
      "Epoch 00031: val_my_ccc_loss did not improve\n",
      "\n",
      "Epoch 00032: val_my_ccc_loss did not improve\n",
      "\n",
      "Epoch 00033: val_my_ccc_loss did not improve\n",
      "\n",
      "Epoch 00034: val_my_ccc_loss did not improve\n",
      "\n",
      "Epoch 00035: val_my_ccc_loss did not improve\n",
      "\n",
      "Epoch 00036: val_my_ccc_loss did not improve\n",
      "\n",
      "Epoch 00037: val_my_ccc_loss did not improve\n",
      "\n",
      "Epoch 00038: val_my_ccc_loss did not improve\n",
      "\n",
      "Epoch 00039: val_my_ccc_loss did not improve\n",
      "\n",
      "Epoch 00040: val_my_ccc_loss did not improve\n",
      "\n",
      "Epoch 00041: val_my_ccc_loss did not improve\n",
      "\n",
      "Epoch 00042: val_my_ccc_loss did not improve\n",
      "\n",
      "Epoch 00043: val_my_ccc_loss did not improve\n",
      "\n",
      "Epoch 00044: val_my_ccc_loss did not improve\n",
      "\n",
      "Epoch 00045: val_my_ccc_loss did not improve\n",
      "\n",
      "Epoch 00046: val_my_ccc_loss did not improve\n",
      "\n",
      "Epoch 00047: val_my_ccc_loss did not improve\n",
      "\n",
      "Epoch 00048: val_my_ccc_loss did not improve\n",
      "\n",
      "Epoch 00049: val_my_ccc_loss did not improve\n",
      "\n",
      "Epoch 00050: val_my_ccc_loss did not improve\n",
      "arousal 0.8972355644815272 0.008904090368022413 0.1408311207703634 0.06411872539985745\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, HashingVectorizer\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.linear_model import RidgeCV, ElasticNetCV, LassoCV\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.preprocessing import Normalizer, StandardScaler\n",
    "from sklearn import metrics\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras.layers import Dense, Input, Concatenate, Dropout, GaussianDropout\n",
    "from keras.models import Model\n",
    "from keras.regularizers import l2\n",
    "from sklearn.metrics import make_scorer\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "from keras import backend as K\n",
    "\n",
    "def cov_keras(a, b):\n",
    "    return K.sum((a - K.mean(a)) * (b - K.mean(b)))\n",
    "    cov = K.dot(K.transpose(a), b)\n",
    "    return cov#K.sum(cov)\n",
    "\n",
    "EPS = 1e-20\n",
    "\n",
    "def my_ccc(y_true, y_pred):\n",
    "    true_mean = K.mean(y_true)\n",
    "    true_variance = K.var(y_true)\n",
    "    pred_mean = K.mean(y_pred)\n",
    "    pred_variance = K.var(y_pred)\n",
    "    true_std = K.std(y_true)\n",
    "    pred_std = K.std(y_pred)\n",
    "    \n",
    "    rho = K.sum((y_true - true_mean) * (y_pred - pred_mean)) / \\\n",
    "        (K.sqrt(K.sum(K.square(y_true - true_mean))) * \n",
    "         K.sqrt(K.sum(K.square(y_pred - pred_mean))) + EPS)\n",
    "    \n",
    "    std_predictions = K.std(y_pred)\n",
    "\n",
    "    std_gt = K.std(y_true)\n",
    "\n",
    "    ccc = (2 * rho * std_gt * std_predictions) / (\n",
    "        K.square(std_predictions) + K.square(std_gt) +\n",
    "        K.square(pred_mean - true_mean) + EPS)\n",
    "\n",
    "    return ccc\n",
    "\n",
    "def my_ccc_loss(y_true, y_pred):\n",
    "    return 1 - my_ccc(y_true, y_pred)\n",
    "\n",
    "labels = ['arousal', 'valence']\n",
    "#labels = ['valence']\n",
    "\n",
    "val_preds_per_label = {}\n",
    "ts_preds_per_label = {}\n",
    "\n",
    "for l in labels[::-1]:\n",
    "    activation = 'sigmoid' if l == 'arousal' else 'tanh'\n",
    "\n",
    "    tr_y_l = tr_y[l].values\n",
    "    val_y_l = val_y[l].values\n",
    "\n",
    "    vec = TfidfVectorizer(ngram_range=(1, 3), min_df=2, sublinear_tf=l == 'arousal')\n",
    "    vec.fit(list(val_X_POS) + list(ts_X_POS))# if l == 'arousal' else list(ts_X_POS))\n",
    "\n",
    "    X_counts = vec.transform(tr_X_POS)\n",
    "    X_ = np.hstack((X_counts.todense(),\n",
    "                    tr_vader,))\n",
    "\n",
    "    X_val = np.hstack((vec.transform(val_X_POS).todense(),\n",
    "                       val_vader,))\n",
    "    X_ts = np.hstack((vec.transform(ts_X_POS).todense(),\n",
    "                       ts_vader,))\n",
    "\n",
    "    input_bow = Input((X_counts.shape[1],), name='bow')\n",
    "    input_fts = Input((tr_vader.shape[1],), name='fts')\n",
    "    \n",
    "    last_bow = input_bow\n",
    "    last_bow = Dropout(0.10)(last_bow)\n",
    "    last_bow = Dense(10, activation='relu' if l == 'arousal' else activation,\n",
    "                     #kernel_regularizer=l2(1e-1)#e-1)\n",
    "                    )(last_bow)\n",
    "    \n",
    "    last_fts = input_fts\n",
    "    #last_fts = Dropout(0.1)(last_fts)\n",
    "    last_fts = Dense(5, activation='relu'\n",
    "                     #kernel_regularizer=l2(1e-1)\n",
    "                    )(last_fts)\n",
    "    last = Concatenate()([last_bow, last_fts])\n",
    "\n",
    "    output = Dense(1, activation=activation)(last)\n",
    "    model = Model(inputs=[input_bow, input_fts], outputs=[output])\n",
    "    model.compile(optimizer='adam', metrics=[my_ccc, my_ccc_loss],\n",
    "                  loss=my_ccc_loss)\n",
    "    \n",
    "    model.summary()\n",
    "    \n",
    "    model.fit({'bow': X_counts, 'fts': tr_vader}, tr_y_l,\n",
    "              epochs=50,\n",
    "              validation_data=({'bow': vec.transform(val_X_POS).todense(),\n",
    "                                'fts': val_vader}, val_y_l),\n",
    "              callbacks=[ModelCheckpoint('model-%s.h5' % l,\n",
    "                                         monitor='val_my_ccc_loss',\n",
    "                                         save_best_only=True, verbose=1)],\n",
    "              verbose=0)\n",
    "    \n",
    "    model.load_weights('model-%s.h5' % l)\n",
    "\n",
    "    tr_preds = model.predict({'bow': vec.transform(tr_X_POS).todense(),\n",
    "                              'fts': tr_vader}).reshape(len(X_))\n",
    "\n",
    "    val_preds = model.predict({'bow': vec.transform(val_X_POS).todense(),\n",
    "                               'fts': val_vader}).reshape(len(X_val))\n",
    "    ts_preds = model.predict({'bow': vec.transform(ts_X_POS).todense(),\n",
    "                              'fts': ts_vader}).reshape(len(X_ts))\n",
    "\n",
    "    val_preds_per_label[l] = val_preds\n",
    "    ts_preds_per_label[l] = ts_preds\n",
    "\n",
    "    print(l,\n",
    "          ccc(tr_y_l, tr_preds)[0],\n",
    "          metrics.mean_squared_error(tr_y_l, tr_preds),\n",
    "          ccc(val_y_l, val_preds)[0],\n",
    "          metrics.mean_squared_error(val_y_l, val_preds),\n",
    "          )\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preds2csv(csv_fn, gt_file_fn, preds_arousal, preds_valence):\n",
    "    df_sample = pd.read_csv(gt_file_fn)\n",
    "    columns = ['video', 'utterance', 'arousal', 'valence']\n",
    "    data = {}\n",
    "    data['video'] = df_sample['video']\n",
    "    data['utterance'] = df_sample['utterance']\n",
    "    data['arousal'] = preds_arousal\n",
    "    data['valence'] = preds_valence\n",
    "    df_preds = pd.DataFrame(data, columns=columns)\n",
    "    df_preds.to_csv(csv_fn, sep=',', index=False)\n",
    "\n",
    "valence_val_preds = np.ones(val_mask.shape[0], dtype=np.float)\n",
    "valence_val_preds[val_mask] = val_preds_per_label['valence']\n",
    "valence_val_preds[~val_mask] = np.nan\n",
    "\n",
    "arousal_val_preds = np.ones(val_mask.shape[0], dtype=np.float)\n",
    "arousal_val_preds[val_mask] = val_preds_per_label['arousal']\n",
    "arousal_val_preds[~val_mask] = np.nan\n",
    "\n",
    "#valence_ts_preds = np.ones(ts_mask.shape[0], dtype=np.float)\n",
    "valence_ts_preds = ts_preds_per_label['valence']\n",
    "valence_ts_preds[~ts_mask] = np.nan\n",
    "\n",
    "#arousal_ts_preds = np.ones(ts_mask.shape[0], dtype=np.float)\n",
    "arousal_ts_preds = ts_preds_per_label['arousal']\n",
    "arousal_ts_preds[~ts_mask] = np.nan\n",
    "\n",
    "preds2csv('val_preds_kelwin.csv', 'omg_ValidationVideos.csv', arousal_val_preds, valence_val_preds)\n",
    "preds2csv('ts_preds_kelwin.csv', 'omg_TestVideos_WithoutLabels.csv', arousal_ts_preds, valence_ts_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
